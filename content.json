[{"title":"shared_ptr和weak_ptr","date":"2017-09-22T00:53:09.000Z","path":"2017/09/22/shared-ptr和weak-ptr/","text":"shared_ptr线程安全性 shared_ptr 本身不是 100% 线程安全的。它的引用计数本身是安全且无锁的，但对象的读写则不是，因为 shared_ptr 有两个数据成员，读写操作不能原子化。根据文档，shared_ptr 的线程安全级别和内建类型、标准库容器、string 一样，即： 一个 shared_ptr 实体可被多个线程同时读取； 两个的 shared_ptr 实体可以被两个线程同时写入，“析构”算写操作； 要从多个线程读写同一个 shared_ptr 对象，那么需要加锁。 用法12345678shared_ptr&lt;int&gt; sp(new int(10)); //一个指向整数的shared_ptr assert(sp.unique()); //现在shared_ptr是指针的唯一持有者 shared_ptr&lt;int&gt; sp2 = sp; //第二个shared_ptr,拷贝构造函数 assert(sp == sp2 &amp;&amp; sp.use_count() == 2); //两个shared_ptr相等,指向同一个对象,引用计数为2 *sp2 = 100; //使用解引用操作符修改被指对象 assert(*sp == 100); //另一个shared_ptr也同时被修改 sp.reset(); //停止shared_ptr的使用 assert(!sp); //sp不再持有任何指针(空指针) 提示:shared_ptr可作为容器的元素,重载了比较和拷贝操作符,auto_ptr不可以 使用陷阱意外延长声明周期 shared_ptr是强引用,只要有一个指向对象的shared_ptr存在,该对象就不会析构. 要注意bind函数,bind会把实参拷贝一份,意外延长对象生命周期 函数参数 我们用const引用来传递类型为shared_ptr的函数参数 析构所在的线程 对象的析构是同步的,当最后一个指向x的shared_ptr离开其作用域的时候,x会同时在同一个线程析构,这个线程不一定是对象诞生的线程,如果析构比较耗时,并且在关键线程中析构,那么会拖累线程的速度, 解决办法是我们可以单独开一个线程专门用来析构,通过一个BlockingQueue","tags":[{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"},{"name":"stl","slug":"stl","permalink":"http://yoursite.com/tags/stl/"}]},{"title":"服务器项目关键组件","date":"2017-08-31T01:52:28.000Z","path":"2017/08/31/服务器项目关键组件/","text":"定时器话说网络程序通常需要处理的三类事件:第一是IO事件,第二是信号,第三就是定时事件,比如定期检测一个客户连接的状态,定时指的是一段时间后触发某段代码的机制.为了实现一个定时器容器,我们选择用链表来实现,可按触发时间来排序存储,每个节点都是一个定时器,储存着: 触发时间和触发事件 所处理的对象 上一个和下一个定时器的位置 再设计一个脉搏函数,每次间隔最小时间后就调用,然后将容器中所有到时的定时器触发. 时间轮如果按上述方式实现定时器,则插入的时间为O(n),效率随着定时器增加而降低,所以我们根据哈希的思想,用空间换时间,改用时间轮的方法.用两个轮,小轮走一圈,大轮走一格,每个槽上都有一个链表,存储时间是该轮整数倍的定时器. 实现代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139//实现一个时间轮定时器,按超时时间排一圈,每个刻度上都有一个链表,存储所有#include&lt;time.h&gt;#include&lt;net_h.h&gt;#include&lt;algorithm&gt;#define BUFFER_SIZE 64class tw_timer;//用户数据结构,客户端地址,socket文件描述符,读缓冲区和定时器struct client_data&#123; sockaddr_in address; int sockfd; char buf[BUFFER_SIZE]; tw_timer* timer;&#125;;class tw_timer&#123;public: tw_timer():rotation(-1),time_slot(-1),prev(nullptr),next(nullptr)&#123;&#125; //tw_timer(tw_timer&amp;); tw_timer(int ro,int ts):rotation(ro),time_slot(ts),prev(nullptr),next(nullptr)&#123;&#125;private: //时间轮转多少圈后生效 int rotation; //属于哪个槽 int time_slot; void (*cb_func)(client_data*); client_data* user_data; tw_timer* prev; tw_timer* next;&#125;;class tw_wheels&#123;public: tw_wheels():curr_slot(-1)&#123; fill_n(this-&gt;wheel,nullptr,sizeof(wheel)); &#125; ~tw_wheels();// void addtimer(tw_timer&amp;); void addtimer(tw_timer* ,tw_timer* ); void del_timer(tw_timer*); void work(int ,int);//让某一个槽上的所有定时器工作 void set_timer(tw_timer,int time_slot,int rotation); void tick();private: //void addtimer(tw_timer* head,); //释放一条链表上的定时器 void release(tw_timer*); static const int K=2;//多少轮子 static const int N=60;//每个轮子多少个槽 static const int SI=1;//最底层轮子的槽间隔为1s tw_timer* wheels[K][N]; int curr_slots[K];//当前指向的槽&#125;;tw_wheels::~tw_wheels()&#123; for(int i=0;i&lt;K;i++)&#123; for(int j=0;j&lt;N;j++) this-&gt;release(wheels[i][j]); wheels[i][j]=nullptr; &#125;&#125;void tw_wheel::release(tw_timer* head)&#123; if(head==nullptr)return; while(head)&#123; tw_timer* temp=head-&gt;next; del_timer(head); head=temp; &#125;&#125;void tw_wheels::addtimer(int timeout,void(*func)(client_data*))&#123; int rot=0,ts=0,i; for( i=K-1;i&gt;=0;i--)&#123; if(timeout+curr_slots[0])%pow(N,i)==0)&#123; int time=(timeout/pow(N,i)); rot=time/N; ts=(time+this-&gt;curr_slots[i])%N; break; &#125; &#125; tw_timer* new_timer=new tw_timer(rot,ts); new_timer-&gt;cb_run=func; addtimer(i,new_timer);&#125;void tw_wheels::addtimer(int wheelsize,tw_timer* target)&#123; int slotpos=target-&gt;time_slot; if(wheels[wheelsize][slotpos]==nullptr)&#123; wheels[wheelsize][slotpos]=target; &#125;else&#123; tw_timer* p=wheels[wheelsize][slotpos]; wheels[wheelsize][slotpos]=target; target-&gt;next=p; p-&gt;prev=target; &#125;&#125;void tw_wheels::del_timer(tw_timer* obj)&#123; if(obj==nullptr)return; if(obj-&gt;prev)&#123; obj-&gt;prev-&gt;next=obj-&gt;next; &#125; if(obj-&gt;next)&#123; obj-&gt;next-&gt;prev=obj-&gt;prev; &#125; delete obj;&#125;void tw_wheels::tick()&#123; int count=1; for(int i=0;i&lt;K;i++)&#123; if(count&gt;0)&#123; curr_slots[i]=(curr_slots[i]+count)%N; work(i,curr_slots[i]); &#125; count=(curr_slots[i])/N; &#125;&#125;void tw_wheels::work(int wheelsize,int slotpos)&#123; tw_timer* cur=wheels[wheelsize][slotpos]; while(cur)&#123; if(cur-&gt;rotation==0)&#123; cur-&gt;cb_func(cur-&gt;user_data); tw_timer* p=cur; cur=cur-&gt;next; del_timer(p); &#125;else&#123; cur-&gt;rotation--; cur=cur-&gt;next; &#125; &#125;&#125; 除了时间轮之外,还有的实现方法为时间堆. 信号量信号量是用来解决多进程之间的同步问题,总共有三个系统调用:semget,semop,semctl 12#include&lt;sys/sem.h&gt;int semget(key_t key,int num_sems,int sem_flags); key参数用来全局唯一表示一个信号量集,要通过信号量通信的进程需要使用相同的键值来创建/获取该信号量.num_sems指定要创建/获取的信号量集中信号量的数目,获取信号量可设置0\\sem_flags指定一组标志semget成功返回一个正整数值,他是信号量集的标示符,创建信号量集内核中关联的数据结构体semid_ds将被创建:1234567891011121314151617#include&lt;sys/sem.h&gt;struct ipc_perm&#123; key_t key;//键值 uid_t uid;//所有者的有效用户id gid_t gid;//所有者的有效组id uid_t cuid; gid_t cgid; mode_t mode;//访问权限&#125;;struct semid_ds&#123; struct ipc_perm sem_perm;//信号量的操作权限 unsigned long int sem_nsems;//信号量数目 time_t sem_otime;//最后一次调用semop的时间 time_t sem_ctime;//最后一次调用semctl的时间&#125;; semop系统调用改变信号量的值,主要改变内核中如下变量:unsigned short semval;//信号量的值unsigned short semzcnt; //等待信号量值变为0的进程数量unsigned short semncnt;//等待信号量pid_t sempid;//最后一次执行semop操作的进程ID12#include&lt;sys/sem.h&gt;int semop(int sem_id,struct sembuf* sem_ops,size_t num_sem_ops); 进程池实现一个进程池,池中所有的子进程都运行着相同的代码,并具有相同的属性,比如优先级,PGID,因为进程池在服务器启动之初就创建好了主进程选择子进程算法有随机选取和轮流选取算法主进程管理所有监听socket,如果有新的连接,通知子进程调用accept接受,无需传递连接socket我们用一个全局管道来统一事件源,为了让进程收到的信号不中断进程,用管道接受信号,然后注册到epoll内核事件表一起监听.每个子进程都有一个管道用来与父进程通信,主要是父进程通过管道通知子进程有新的连接到来. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284#ifndef PROC_POOL_H#define PROC_POOL_H#include\"./server_head.h\"//描述一个子进程的类class process&#123;public: process():m_pid(-1)&#123;&#125; ~process()&#123;&#125;private: pid_t m_pid;//自己的进程id int m_pipefd[2];//用来和父进程通信的管道&#125;;template&lt;typename T&gt;class processpool&#123;private: processpool(int listenfd,int process_number=8);//单例模式,构造函数私有public: static processpool&lt;T&gt;* create(int listenfd,int process_number)&#123; if(m_instance==nullptr)&#123; m_instance=new processpool&lt;T&gt;(listenfd,process_number); &#125; return m_instance; &#125; ~processpool()&#123; delete []this-&gt;m_sub_proc; void run();//启动进程池 void setup_sig_pipe(); void run_child(); void run_parent();pirvate: static const int MAX_PROCESS_NUMBER=16;//进程池最大子进程数量 static const int USER_PER_PROCESS=65536;//每个子进程最多能处理的客户数量 static const int MAX_EVENT_NUMBER=10000;//epoll最多能处理的事件数 int m_process_number;//进程池中的进程总数 int m_idx;//子进程在池中的序号 int m_epollfd;//每个进程都有一个内核事件表, int m_listenfd;//监听socket bool m_stop;//是否运行 process* m_sub_proc; static processpool&lt;T&gt;* m_instance;&#125;:template&lt;typename T&gt;processpool&lt;T&gt;::m_instance=nullptr;//静态成员函数初始化static int sig_pipefd[2];//用于处理进程收到信号的管道(和从父进程收到的信号分开),以实现统一事件源,信号管道//一些功能函数//设置fd为非阻塞 static int setnonblocking(int fd)&#123; int old_option=fcntl(fd,F_GETFL); fcntl(fd,F_SETFL,old_option|O_NONBLOCK); return old_option; &#125;static void addfd(int m_epollfd,int fd)&#123; epoll_event event; event.data.fd=fd; event.event=EPOLLIN|EPOLLET; epoll_ctl(m_epollfd,EPOLL_CTL_ADD,fd,&amp;event); setnonblocking(fd);&#125;static void removefd(int epollfd,int fd)&#123; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,0); close(fd);&#125;static void sig_add(int sig,void(*handler)(int),bool restart=true)&#123; struct sigaction si; memset(&amp;si,0,sizeof(si)); si.sa_handler=handler; si.sa_flags|=restart?SA_RESTART:0; sigfillset(&amp;si.sa_mask);&#125; static void sig_handler(int sig)&#123; int save_errno=errno; send(sig_pipefd[0],static_cast&lt;char*&gt;&amp;sig,1,0);//?为什么只传1个字节 errno=save_errno;&#125;template&lt;typename T&gt;void processpool&lt;T&gt;::processpool(int listenfd,int process_number): m_listenfd(listenfd),m_process_number(process_number), m_idx(-1),(m_stop(false)&#123; assert(process_number&gt;0 &amp;&amp; process_number&lt;=MAX_PROCESS_NUMBER); m_sub_proc=new process[process_number]; for(int i=0;i&lt;process_number;i++)&#123; sockpair(PF_UNIX,SOCK_STREAM,0,m_sub_proc[i].m_pipefd); m_sub_proc[i].m_pid=fork(); if(m_sub_proc[i].m_pid==0)&#123; m_idx=i; close(m_sub_proc[i].m_pipefd[0]);//关闭写端 break; &#125;else&#123; close(m_sub_proc[i].m_pipefd[1]) &#125; &#125; &#125;template&lt;typename T&gt;processpool&lt;T&gt;::setup_sig_pipe()&#123; this-&gt;epollfd=epoll_create(5); assert(this-&gt;epollfd!=-1); assert(sockpair(PF_UNIX,SOCK_STREAM,0,sig_pipefd)); setnonblocking(sig_pipefd[1]); addfd(m_epollfd,sig_pipefd[0]); sig_add(SIGCHLD,sig_handler); sig_add(SIGTERM,sig_handler); sig_add(SIGINT,sig_handler); sig_add(SIGPIPE,SIG_IGN);template&lt;typename T&gt;void processpool&lt;T&gt;::run()&#123; if(this-&gt;m_idx!=0)&#123; run_child(); &#125;else&#123; run_parent(); &#125;&#125;//子进程调用epoll_wait,监听到的事件分类处理.template&lt;typename T&gt;void processpool::run_child()&#123; this-&gt;setup_sig_pipe();//第一步统一事件源 epoll_event events[MAX_EVENT_NUMBER]; T* user=new T[USER_PER_PROCESS]; int pipefd=this-&gt;m_sub_proc[m_idx].m_pipefd[0]; while(!this-&gt;m_stop)&#123; int number=epoll_wait(this-&gt;m_epollfd,events,MAX_EVENT_NUMBER,-1); if(number&lt;0&amp;&amp;(errno!=EINTER)&#123; printf(\"epoll failure\\n\"); break; &#125; for(int i=0;i&lt;number;i++)&#123; int sockfd=events[i].data.fd; if((sockfd==pipefd)&amp;&amp;(events[i].events &amp;EPOLLIN)&#123;//管道全双工,我们处理读事件 int client=0; recv(sockfd,(char*)&amp;client,sizeof(client),0); struct sockaddr_in client_address; socklen_t client_addrlength=sizeof(client_address); int connfd=accept(this-&gt;m_listenfd,(struct sockaddr*)&amp;client_address,&amp;client_addrlength); addfd(this-&gt;m_epollfd,connfd); user[connfd].init(m_epollfd,connfd,client_address);//具体处理方法的初始化 &#125;else if((sockfd==sig_pipefd[1])&amp;&amp;(events[i].event &amp; EPOLLIN))&#123; //处理信号,可能一次收到多个信号 int sig; char signals[1024]; int ret=recv(sockfd,signals,sizeof(signals),0); for(int i=0;i&lt;ret;i++)&#123; switch(signals[i])&#123;//信号占一个字节 case SIGCHLD://子进程终止信号 &#123; pid_t pid; int stat; while((pid=waitpid(-1,&amp;stat,WNOHANG) )&gt;0)&#123; continue; &#125; break; &#125; case SIGTERM: case SIGINT://终止信号 &#123; this-&gt;m_stop=true; break; &#125; default: &#123; break; &#125; &#125; &#125; &#125; else if(events[i].events &amp; EPOLLIN)&#123;//其他类型描述符,肯定是已连接描述符上请求到来 user[sockfd].process(); &#125;else&#123; continue; &#125; &#125; &#125; delete[] user; user=nullptr; close(pipefd); close(m_epollfd);&#125;template&lt;typname T&gt;void processpool&lt;T&gt;::run_parent()&#123; this-&gt;setup_sig_pipe(); addfd(this-&gt;m_epollfd,this-&gt;m_listenfd); epoll_event events[USER_PER_PROCESS]; int new_connfd=1; int sub_process_counter=0; while(!m_stop)&#123; int number=epoll_wait(this-&gt;m_epollfd,events,MAX_EVENT_NUMBER,-1); if((number&lt;0)&amp;&amp;(errno!=EINTER))&#123; printf(\"epoll failure\\n\"); break; &#125; for(int i=0;i&lt;number;i++)&#123; int sockfd=events[i].data.fd; if((sockfd==this-&gt;m_listenfd)&#123; //接下来通过随机选取算法选择一个子进程通知. int i=sub_process_counter; do&#123; if(m_sub_process[i].m_pid!=-1)&#123; break; &#125; i=(i+1)%m_process_number; &#125;while(i!=sub_process_counter); if(m_sub_process[i].m_pid==-1)&#123; m_stop=true; break; &#125; sub_process_counter=(i+1)%m_process_number; send(m_sub_process[i].m_pipefd[0],(char*)&amp;new_coon,sizeof(new_conn),0);//写入一个数值表示有新连接 printf(\"send requeset to child %d\\n\",i); &#125; else if((sockfd=sig_pipefd[1])&amp;&amp;(events[i].event&amp;EPOLLIN)&#123;//处理自己收到的信号 int sig; char signals[1024]; ret=recv(sig_pipefd[0],signals,sizeof(signals),0); if(ret&lt;=0)&#123; continue; &#125;else&#123; for(int i=0;i&lt;ret;i++)&#123; switch(signals[i])&#123; case SIGCHLD: &#123; pid_t pid; int stat; while((pid=waitpid(-1,&amp;stat,WNOHANG) )&gt;0)&#123; for(int i=0;i&lt;m_process_number;i++)&#123;//关闭通信管道的写端 if(this-&gt;m_sub_process[i].m_pid==pid)&#123; close(this-&gt;m_sub_process.m_pipefd[0]); m_sub_process[i].m_pid=-1; &#125; &#125; &#125; //如果没有子进程存在,则父进程也退出 m_stop=true; for(int i=0;i&lt;process_number;i++)&#123; if(m_sub_process[i].m_pid!=-1)&#123; m_stop=false; break; &#125; &#125; break; &#125; case SIGTERM: case SIGINT: &#123; printf(\"kill all child now\\n\"); for(int i=0;i&lt;m_process_number;i++)&#123; int pid=m_sub_process[i].m_pid; if(pid!=-1)&#123; kill(pid,SIGTERM); &#125; &#125; break; &#125; default: break; &#125; &#125; &#125; &#125; else&#123; continue; &#125; &#125; &#125; close(m_epollfd);&#125;#endif 线程同步为了使用方便,我们将posix线程标准下用来同步线程的三种锁进行封装,信号量,互斥量,条件变量 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#ifndef LOCKER_H#define LOCKER_H#include\"./server_head.h\"class cond;class sem&#123;public: sem()&#123; if(sem_init(&amp;m_sem,0,0)!=0)&#123; throw std::exception(); &#125; &#125; ~sem()&#123; sem_destroy(&amp;m_sem); &#125; bool wait()&#123; return sem_wait(&amp;m_sem)==0; &#125; bool post()&#123; return sem_post(&amp;m_sem)==0; &#125;private: sem_t m_sem;&#125;;class locker&#123;public: friend class cond; locker()&#123; init(); &#125; ~locker()&#123; release(); &#125; void init()&#123; if(pthread_mutex_init(&amp;m_mutex,NULL)!=0) throw std::exception(); &#125; void release()&#123; pthread_mutex_destroy(&amp;m_mutex); &#125; bool lock()&#123; return pthread_mutex_lock(&amp;m_mutex)==0; &#125; bool unlock()&#123; return pthread_mutex_lock(&amp;m_mutex)==0; &#125;private: pthread_mutex_t m_mutex; pid_t m_pid;&#125;;class cond&#123;public: cond()&#123; m_lock.init(); if(!init())&#123; m_lock.release(); &#125; &#125; ~cond()&#123; m_lock.release(); this-&gt;release(); &#125; bool init()&#123; return pthread_cond_init(&amp;m_cond,NULL)==0; &#125; void release()&#123; pthread_cond_destroy(&amp;m_cond); &#125; bool signal()&#123; return pthread_cond_signal(&amp;m_cond)==0; &#125; bool broadcast()&#123; return pthread_cond_broadcast(&amp;m_cond)==0; &#125; bool wait()&#123; int ret=0; m_lock.lock(); ret=pthread_cond_wait(&amp;m_cond,&amp;m_lock.m_mutex); m_lock.unlock(); return ret==0; &#125;private: locker m_lock; pthread_cond_t m_cond;&#125;;#endif 线程池","tags":[{"name":"socket","slug":"socket","permalink":"http://yoursite.com/tags/socket/"},{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"高性能服务器框架","date":"2017-08-27T06:59:39.000Z","path":"2017/08/27/高性能服务器框架/","text":"两种高效的事件处理方式 Reactor模式Reactor模式要求主线程只负责监听文件描述符的是否有事件发生,有的话就通知工作线程去处理,主线程本身不做任何实质性工作,接受新连接(accept),处理客户请求均在工作线程中完成使用同步I/O模型的话流程如下: 主线程往epoll内核事件表中注册socket上的读就绪事件(这步先不用注册写) 调用epoll_wait等待socket上有数据可读. 当socket上有数据可读时,epoll_wait通知主线程,主线程则将socket可读事件放入请求队列 线程池中某个睡眠状态的线程被唤醒,从socket读取数据,并处理客户请求,然后往epoll内核事件表中注册socket上的写就绪事件. 主线程调用epoll_wait等待socket可写 当socket可写时,epoll_wait通知主线程,主线程则将socket可写事件放入请求队列 线程池中某个睡眠状态的线程被唤醒,往socket写入服务器处理客户请求的结果 注意一点,读写用两个线程分开执行,但线程不区分只读线程和只写线程. Proactor模式Proactor模式相反,要求主线程处理所有的I/O操作,工作线程仅仅负责业务逻辑.使用异步I/O模型实现的Proactor模式工作流程: 主线程调用aio_read函数想内核注册socket上的读完成事件,并告诉内核用户读缓冲区的位置(这是为了能让读到的内容复制到用户缓冲区,如何实现),以及读操作完成时如何通知应用程序(一种方法用signal) 主线程继续处理其他逻辑 读入用户缓冲区后,内核将向应用程序发送一个信号,以通知应用程序数据可用. 收到信号,应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求,工作线程处理完客户请求后,调用aio_write(异步)函数向内核注册写完成事件,并告诉内核用户写缓冲区的位置,以及写操作完成时如何通知应用程序.(信号) 主线程继续处理其他逻辑 当用户缓冲区的数据被写入socket之后,内核将向应用程序,发送一个信号,以通知应用程序数据已经发送完毕. 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理,比如决定是否关闭socket. 同步I/O实现Proactor模式主线程执行数据读写操作,主线程向工作线程通知这一”完成事件”.那么从工作线程的角度来看,他们就直接获得了数据读写的结果,接下来要做的只是对读写的结果进行逻辑处理.与Reactor唯一的不同就是主线程读完socketfd中的内容,打包成请求对象入请求队列,然后唤醒工作线程来处理,然后向epoll中注册写就绪事件,接着主线程执行写操作. 两种高效的并发模式并发模式主要用来解决I/O密集型的情况,如果是计算密集型,用多线程反而由于任务切换过频繁导致效率降低.I/O操作的速度没有CPU的计算速度快,所以阻塞在I/O上会浪费CPU计算时间.如果一个线程阻塞在I/O,那么由操作系统调度该线程CPU占用率减小,给其他线程提高CPU占用率. 半同步/半异步模式在这种模式中,同步线程主要用来处理客户逻辑,相当于逻辑单元,异步线程用来处理IO事件,相当于IO处理单元.异步线程(主线程)监听到请求,封装成请求对象插入请求队列,请求队列将通知同步工作线程来处理,同步工作线程不会被中断. 半同步半反应堆模式特点: 异步线程只有一个，由主线程来充当，负责监听所有socket上的事件。 如果有新的连接请求，主线程就接受之，以得到新的连接socket 在epoll内核事件表中注册该socket上的读写事件 如果连接socket上有读写事件发生，即有新的客户请求到来或有数据要发送到客户端，主线程就将该连接socket插入请求队列。 所有工作线程都睡眠在请求队列上，当有任务到来时，它们将通过竞争获得任务的接管权。 缺点: 主线程和工作线程共享同一个请求队列,所以主线程在插入请求对象时,会加锁保护队列,使得工作线程无法读取请求对象.浪费CPU时间. 工作线程同一时间只能处理一个客户请求. 改进:主线程监听是否有新的连接,有的话就分配给工作线程,工作线程调用epoll_wait,将得到的新连接的事件添加到自己的epoll内核注册表中. 领导者/追随者模式领导者线程用来监听IO事件,如果检测到事件,首先推举一个新的追随者线程为领导者线程,然后去处理事件.领导者追随者模式包含如下几个组件:句柄集,线程集,事件处理器,和具体的事件处理器. 句柄集:用来表示IO资源,也就是文件描述符的集合 线程集:所有线程的管理者,其中的线程处于三种状态之一,leader,follower,processing. 事件处理器:一系列的回调函数,这些回调函数用来处理业务逻辑.用之前需要绑定一个文件描述符,这样有事件发生,就执行该事件处理器的回调函数. 具体的事件处理器:事件处理的派生类,重载父类的回调函数,用来处理特定的任务. 接下来说明对于http的报文如何解析. 有限状态机有限状态机就是每次循环执行和状态相对应的逻辑,然后转移到下一种状态,比如在http报文分析中,我们将主状态分为读请求行和读头部字段,从状态分为每行的读取状态:读完一行,行不完整,行有错误.然后每次循环读一行,对主状态switch,先解析请求行,然后转移主状态,再次循环执行解析头部字段. 提高性能的其他建议 池化思想:不要动态分配线程进程,用事先分配好的线程池或进程池,减小系统调用开销 数据复制:避免不必要的数据复制,特别在用户空间和内核空间之间. 上下文切换和锁:不要使用过多线程,减小上下文切换的开销.不要频繁使用锁,会降低线程的并发性.","tags":[{"name":"c","slug":"c","permalink":"http://yoursite.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"}]},{"title":"自制radix_tree","date":"2017-08-21T07:21:12.000Z","path":"2017/08/21/自制radix-tree/","text":"介绍前缀树radix tree,中文基数树,是用来解决hash冲突和hash表的设计,前缀树是一种有序树,用于保存关联数组,键一般都为字符串.每个节点的所有子孙都有相同的前缀.最后所有的叶子节点保存了要存储的元素.前缀树经常用于搜索提示,比如输入一个网址,可以自动搜索出可能的选择.前缀树的问题在于可能过于稀疏,空间浪费严重.比如几个字符串有相同某段前缀,但是如果按每个字符来分的话,会出现很多没有用的节点. 前缀压缩树为了解决问题,出现了压缩前缀树,对于基数树的每个节点,如果该节点是唯一的儿子的话,就和父节点合并.下面就来自己实现一个基数树容器. 组件首先,是一颗树,就必须有节点类的定义,radix_tree_node,其次,既然是容器,我们需要一个迭代器的类,最后是radix_tree本身. 节点第一,节点要存什么,节点要存的信息有键和要存的元素,我们可以用一个pair来实现,其次,节点要有子节点,由于子节点数量不确定,我们可以用map来存,如果用线性表来存访问速度就会是O(n).为了方便还存了父节点和键.声明代码如下:12345678910111213141516171819202122template &lt;typename K, typename T&gt;class radix_tree_node &#123; friend class radix_tree&lt;K, T&gt;; friend class radix_tree_it&lt;K, T&gt;; typedef std::pair&lt;const K, T&gt; value_type; typedef typename std::map&lt;K, radix_tree_node&lt;K, T&gt;* &gt;::iterator it_child;private://构造和析构 radix_tree_node() : m_children(), m_parent(NULL), m_value(NULL), m_depth(0), m_is_leaf(false), m_key() &#123; &#125; radix_tree_node(const value_type &amp;val); ~radix_tree_node();//类成员 std::map&lt;K, radix_tree_node&lt;K, T&gt;*&gt; m_children; radix_tree_node&lt;K, T&gt; *m_parent; value_type *m_value; int m_depth; bool m_is_leaf; K m_key;&#125;; 重载析构在初始化对象的时候，根据参数的不同，使用不同的构造函数，这里我们写了重载构造函数和删除对象时的析构函数： 12345678910111213141516171819202122template &lt;typename K, typename T&gt;radix_tree_node&lt;K, T&gt;::radix_tree_node(const value_type &amp;val) : m_children(), m_parent(NULL), m_value(NULL), m_depth(0), m_is_leaf(false), m_key()&#123; m_value = new value_type(val);&#125;template &lt;typename K, typename T&gt;radix_tree_node&lt;K, T&gt;::~radix_tree_node()&#123; it_child it; for (it = m_children.begin(); it != m_children.end(); ++it) &#123; delete it-&gt;second; &#125; delete m_value;&#125; 要注意释放申请的内存 迭代器我们要定义树的迭代器,首先迭代器能访问树节点上保存的信息(键值),不能访问其他信息,自己定义的迭代器最好继承标准库迭代器std::iterator: 1234567891011121314151617181920212223242526template &lt;typename K, typename T&gt;//要继承的iterator实例化参数要加std::forward_iterator_tag,因为树是向前迭代器class radix_tree_it : public std::iterator&lt;std::forward_iterator_tag, std::pair&lt;K, T&gt; &gt; &#123; friend class radix_tree&lt;K, T&gt;;public: radix_tree_it() : m_pointee(0) &#123; &#125; radix_tree_it(const radix_tree_it&amp; r) : m_pointee(r.m_pointee) &#123; &#125; radix_tree_it&amp; operator=(const radix_tree_it&amp; r) &#123; m_pointee = r.m_pointee; return *this; &#125; ~radix_tree_it() &#123; &#125; std::pair&lt;const K, T&gt;&amp; operator* () const; std::pair&lt;const K, T&gt;* operator-&gt; () const; const radix_tree_it&lt;K, T&gt;&amp; operator++ (); radix_tree_it&lt;K, T&gt; operator++ (int); // const radix_tree_it&lt;K, T&gt;&amp; operator-- (); bool operator!= (const radix_tree_it&lt;K, T&gt; &amp;lhs) const; bool operator== (const radix_tree_it&lt;K, T&gt; &amp;lhs) const;private: radix_tree_node&lt;K, T&gt; *m_pointee; radix_tree_it(radix_tree_node&lt;K, T&gt; *p) : m_pointee(p) &#123; &#125; radix_tree_node&lt;K, T&gt;* increment(radix_tree_node&lt;K, T&gt;* node) const; radix_tree_node&lt;K, T&gt;* descend(radix_tree_node&lt;K, T&gt;* node) const;&#125;; 我们重载了一些操作符,接下来看如何实现 操作符123456789101112131415161718192021222324252627282930313233343536373839template &lt;typename K, typename T&gt;std::pair&lt;const K, T&gt;&amp; radix_tree_it&lt;K, T&gt;::operator* () const&#123; return *m_pointee-&gt;m_value;&#125;template &lt;typename K, typename T&gt;std::pair&lt;const K, T&gt;* radix_tree_it&lt;K, T&gt;::operator-&gt; () const&#123; return m_pointee-&gt;m_value;&#125;template &lt;typename K, typename T&gt;bool radix_tree_it&lt;K, T&gt;::operator!= (const radix_tree_it&lt;K, T&gt; &amp;lhs) const&#123; return m_pointee != lhs.m_pointee;&#125;template &lt;typename K, typename T&gt;bool radix_tree_it&lt;K, T&gt;::operator== (const radix_tree_it&lt;K, T&gt; &amp;lhs) const&#123; return m_pointee == lhs.m_pointee;&#125;template &lt;typename K, typename T&gt;const radix_tree_it&lt;K, T&gt;&amp; radix_tree_it&lt;K, T&gt;::operator++ ()&#123; if (m_pointee != NULL) m_pointee = increment(m_pointee); return *this;&#125;template &lt;typename K, typename T&gt;radix_tree_it&lt;K, T&gt; radix_tree_it&lt;K, T&gt;::operator++ (int)&#123; radix_tree_it&lt;K, T&gt; copy(*this); ++(*this); return copy;&#125; 实现increment和descend关键在于如何遍历树的叶子节点,从一个叶子节点要寻找的下一个节点要么是自己的下一个兄弟节点,需要通过父节点来访问到,要么自己已经是最后一个兄弟节点,这时候需要找父节点的下一个兄弟节点,再往下找到叶子节点 123456789101112131415161718192021222324252627282930template &lt;typename K, typename T&gt;radix_tree_node&lt;K, T&gt;* radix_tree_it&lt;K, T&gt;::increment(radix_tree_node&lt;K, T&gt;* node) const&#123; radix_tree_node&lt;K, T&gt;* parent = node-&gt;m_parent; if (parent == NULL) return NULL; typename radix_tree_node&lt;K, T&gt;::it_child it = parent-&gt;m_children.find(node-&gt;m_key); assert(it != parent-&gt;m_children.end()); ++it; if (it == parent-&gt;m_children.end()) return increment(parent); else return descend(it-&gt;second);&#125;template &lt;typename K, typename T&gt;radix_tree_node&lt;K, T&gt;* radix_tree_it&lt;K, T&gt;::descend(radix_tree_node&lt;K, T&gt;* node) const&#123; if (node-&gt;m_is_leaf) return node; typename radix_tree_node&lt;K, T&gt;::it_child it = node-&gt;m_children.begin(); assert(it != node-&gt;m_children.end()); return descend(it-&gt;second);&#125; 接下来要实现radix_tree,也是核心部分. radix_tree","tags":[{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"创建博客网站项目启动","date":"2017-06-25T10:43:58.000Z","path":"2017/06/25/创建博客网站项目启动/","text":"题外 一个多月没写博客了,最近也没怎么看书,搞了几个算法比赛也一无所获,感觉自己越来越懒了,从现在开始给自己一个规定,每周六必须定期写一篇,如果没东西总结归纳说明这周就没干什么事情. web项目 这周开始准备跟着狗书还有网上资源,做一个社交博客网站,从这个项目里期望能对web开发整个框架有一个具体的认识.所用到的技术和要点如下: Python语法基础,重点在于装饰器 Flask框架学习 数据库基础,掌握基本sql语言 前端基础,html语法和css样式 服务器和http协议 目前刚刚看完Python基础语法和数据库的基本操作,但是Python写程序还很生涩,要多加练习,接下来计划一周完成flask基础学习和前端入门,加上博客的各个模块的简要实现.加油!","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"sql","slug":"sql","permalink":"http://yoursite.com/tags/sql/"},{"name":"web 开发","slug":"web-开发","permalink":"http://yoursite.com/tags/web-开发/"},{"name":"Flask框架","slug":"Flask框架","permalink":"http://yoursite.com/tags/Flask框架/"}]},{"title":"select,poll和epoll","date":"2017-05-17T02:18:12.000Z","path":"2017/05/17/select-poll和epoll-1/","text":"selectselect函数允许进程指示内核等待多个事件中的任何一个发生,只有在一个或多个事件(描述符状态变化)发生或者阻塞时间超时会返回.select的接口如下: #include&lt;sys/select.h&gt; #include&lt;sys/time.h&gt; int select(int maxfdp1,fd_set* readset,fd_set* writeset,fd_set* exceptset,const struct timeval* timeout); 其中第一个参数表示所有关心的描述符总数,即后面三个集合中描述符的数量和,后面三个参数分别表示测试读写和异常条件的描述符.最后一个参数表示最大阻塞时间,即超过时间没有描述符就绪则返回. struct timeval{ long tv_sec;// 秒数 long tv_usec;// 微妙数 }; fd_set这个结构的初始化和赋值使用已定义的宏: void FD_ZERO(fd_set \\*fdset); //初始化清零 void FD_SET(int fd,FD_SET \\*fdset); //设置某一位描述符 void FD_CLR(int fd,FD_SET \\*fdset); //清除某一位描述符 int FD_ISSET(int fd,FD_SET \\*fdset); //测试是否有指定位描述符 对于select返回某个套接字就绪的条件,总结如下: 条件 可读吗? 可写吗? 异常吗? 有数据可读 Y 关闭连接的读一半 Y 给监听套接口准备好新连接 Y 有可用于写的空间 Y 关闭连接的写一半 Y 待处理错误 Y Y TCP带外数据 Y 说明:关闭套接字的读一半后,执行读操作会立即返回EOF,所以也算作可读状态,关闭写一半,执行写操作会立即返回SIGPIPE信号,算作可写状态. pollpoll功能和select相似,在处理流设备时,能提供额外信息.poll函数接口原型: #include&lt;poll.h&gt; int poll(struct pollfd *fdarray,unsigned long nfds,int timeout); 结构体 pollfd的定义: struct pollfd{ int fd; //要测试的描述符 short events; //感兴趣的事件(读写异常) short revents; //发生的事件 }; POSIX定义了events标志的一些常值 常值 作为events输入吗 作为revents输出吗 说明 POLLIN Y Y 普通或优先级带数据可读 POLLRDNORM Y Y 普通数据可读 POLLOUT Y Y 普通数据可写 POLLERR Y 发生错误 参数nfds表示套接字的数量 epollselect的缺点有两个,第一,针对每个描述符的循环语句.第二,每次调用都要向操作系统传递套接字信息,造成无法优化的负担.为了解决第二个问题,epoll仅向操作系统传递一次监视对象,监视范围或者内容发生变化式只通知发生变化的事项(注意,Linux才支持epoll)epoll实现需要3个函数接口: epoll_create:创建保存epoll文件描述符的空间 epoll_ctl:向空间注册并注销文件描述符 epoll_wait:与select函数类似,等待文件描述符的变化.12345678910111213141516#include&lt;sys/epoll.h&gt;int epoll_create(int size);//成功返回文件描述符，创建的fd保存空间在内核中，size为建议的空间大小，用完需要调用close关闭.int epoll_ctl(int epfd,int op,int fd,struct epoll_event \\*event);//用来添加需要监视的fd。int epoll_wait(int epfd,struct epoll_event \\*events,int maxevents,int timeout);//成功返回就绪fd数量struct epoll_event&#123; __uint32_t events; epoll_data_t data;&#125;typedef union epoll_data&#123; void* ptr; int fd; __uint32_t u32; __uint64_t u64;&#125;epoll_data_t; epoll_ctl中op选项: EPOLL_CTL_ADD EPOLL_CTL_DEL EPOLL_CTL_MOD:更改出册的文件描述符的关注事件发生情况 epoll_events中的events常用值: EPOLLIN:需要读取数据的情况 EPOLLOUT:输出缓冲为空,可以立即发送数据的情况 EPOLLRDHUP:断开连接或者半关闭的情况 EPOLLERR:错误情况 EPOLLLET:以边缘触发的方式 EPOLLONESHOT:发生一次事件后,相应描述符不在收到事件通知(所以需要EPOLL_CTL_MOD选项.再次设置) epoll_wait中events保存就绪的描述符,所以需要给它动态分配缓存区,maxevents用来指示第二个参数最大数量. #include&lt;stdio.h&gt; #include&lt;stdlib.h&gt; #include&lt;sys/socket.h&gt; #include&lt;sys/epoll.h&gt; #include&lt;arpa/inet.h&gt; #include&lt;unistd.h&gt; #include&lt;string.h&gt; const int BUF_SIZE=100; const int EPOLL_SIZE=50; void error_handling(const char* message); int main(int argc,char** argv) { int serv_sock,clnt_sock; struct sockaddr_in serv_adr,clnt_adr; char buf[BUF_SIZE]; struct epoll_event* ep_events; struct epoll_event event; int epfd,event_cnt; if(argc!=2){ printf(&quot;Usage: %s&lt;port&gt;\\n&quot;,argv[0]); exit(1); } serv_sock=socket(PF_INET,SOCK_STREAM,0); memset(&amp;serv_adr,0,sizeof(serv_adr)); serv_adr.sin_family=AF_INET; serv_adr.sin_addr.s_addr=htonl(INADDR_ANY); serv_adr.sin_port=htons(atoi(argv[1])); if(bind(serv_sock,(struct sockaddr*)&amp;serv_adr,sizeof(serv_adr))==-1) error_handling(&quot;bind() error&quot;); if(listen(serv_sock,5)==-1) error_handling(&quot;listen() error&quot;); //创建epoll epfd=epoll_create(EPOLL_SIZE); ep_events=(struct epoll_event*)malloc(sizeof(struct epoll_event)*EPOLL_SIZE); event.events=EPOLLIN; event.data.fd=serv_sock; epoll_ctl(epfd,EPOLL_CTL_ADD,serv_sock,&amp;event); //监听 while(1) { event_cnt=epoll_wait(epfd,ep_events,EPOLL_SIZE,-1); if(event_cnt==-1){ puts(&quot;epoll_wait() error&quot;); break; } for(int i=0;i&lt;event_cnt;i++){ if(ep_events[i].data.fd==serv_sock) { socklen_t adr_sz=sizeof(clnt_adr); clnt_sock=accept(serv_sock,(struct sockaddr*)&amp;clnt_adr,&amp;adr_sz); event.events=EPOLLIN; event.data.fd=clnt_sock; epoll_ctl(epfd,EPOLL_CTL_ADD,clnt_sock,&amp;event); printf(&quot;connected client: %d \\n&quot;,clnt_sock); }else{ int str_len=read(ep_events[i].data.fd,buf,BUF_SIZE); if(str_len==0) { epoll_ctl(epfd,EPOLL_CTL_DEL,ep_events[i].data.fd,NULL); close(ep_events[i].data.fd); printf(&quot;Disconnected client: %d \\n&quot;,ep_events[i].data.fd); }else{ write(ep_events[i].data.fd,buf,str_len); } } } } close(serv_sock); close(epfd); return 0; } void error_handling(const char* message){ fputs(message,stderr); fputc(&apos;\\n&apos;,stderr); exit(1); } 条件触发和边缘出发条件触发:只要满足条件,就触发一个事件(例如缓冲区的数据没有读完,内核会一直通知)边缘触发:每当状态变化时,触发一个事件. “举个读socket的例子，假定经过长时间的沉默后，现在来了100个字节，这时无论边缘触发和条件触发都会产生一个read ready notification通知应用程序可读。应用程序读了50个字节，然后重新调用api等待io事件。这时水平触发的api会因为还有50个字节可读从 而立即返回用户一个read ready notification。而边缘触发的api会因为可读这个状态没有发生变化而陷入长期等待。 因此在使用边缘触发的api时，要注意每次都要读到socket返回EWOULDBLOCK为止，否则这个socket就算废了。而使用条件触发的api 时，如果应用程序不需要写就不要关注socket可写的事件，否则就会无限次的立即返回一个write ready notification。大家常用的select就是属于水平触发这一类，长期关注socket写事件会出现CPU 100%的毛病。 引用自网友博客的总结:epoll的优点：1.支持一个进程打开大数目的socket描述符(FD) select 最不能忍受的是一个进程所打开的FD是有一定限制的，由FD_SETSIZE设置，默认值是2048。对于那些需要支持的上万连接数目的IM服务器来说显 然太少了。这时候你一是可以选择修改这个宏然后重新编译内核，不过资料也同时指出这样会带来网络效率的下降，二是可以选择多进程的解决方案(传统的 Apache方案)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完 美的方案。不过 epoll则没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 2.IO效率不随FD数目增加而线性下降 传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是”活跃”的， 但是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对”活跃”的socket进行 操作—这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有”活跃”的socket才会主动的去调用 callback函数，其他idle状态socket则不会，在这点上，epoll实现了一个”伪”AIO，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上都是活跃的—比如一个高速LAN环境，epoll并不比select/poll有什么效率，相 反，如果过多使用epoll_ctl,效率相比还有稍微的下降。但是一旦使用idle connections模拟WAN环境,epoll的效率就远在select/poll之上了。 3.使用mmap加速内核与用户空间的消息传递。 这点实际上涉及到epoll的具体实现了。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就 很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。而如果你想我一样从2.5内核就关注epoll的话，一定不会忘记手工 mmap这一步的。 4.内核微调 这一点其实不算epoll的优点了，而是整个linux平台的优点。也许你可以怀疑linux平台，但是你无法回避linux平台赋予你微调内核的能力。 比如，内核TCP/IP协议栈使用内存池管理sk_buff结构，那么可以在运行时期动态调整这个内存pool(skb_head_pool)的大小 — 通过echo XXXX&gt;/proc/sys/net/core/hot_list_length完成。再比如listen函数的第2个参数(TCP完成3次握手 的数据包队列长度)，也可以根据你平台内存大小动态调整。更甚至在一个数据包面数目巨大但同时每个数据包本身大小却很小的特殊系统上尝试最新的NAPI网 卡驱动架构。","tags":[{"name":"unp","slug":"unp","permalink":"http://yoursite.com/tags/unp/"},{"name":"unix","slug":"unix","permalink":"http://yoursite.com/tags/unix/"}]},{"title":"5种IO模型总结","date":"2017-05-16T10:20:02.000Z","path":"2017/05/16/5种IO模型总结-1/","text":"在unix环境下,有5种IO模型,前4种属于同步IO: 阻塞式IO 非阻塞式IO IO复用(select和poll,还有更好的epoll) 信号驱动式IO(SIGIO) 异步IO(aio_系列函数) 阻塞式IO最流行的IO模型,默认情况下,所有套接字都是阻塞的,例如read,write,recvfrom.不再赘述(要注意不等于同步) 非阻塞式IO进程把一个套接字设置成非阻塞是在通知内核:当所请求的IO操作非得把本进程投入睡眠才能完成时,不要把本进程投入睡眠,而是返回一个错误.例如调用recvfrom时,如果内核空间无数据报准备好,则立即返回EWOULDBLOCK错误.如果有的话就会阻塞一直到IO完成.(按理论来说这种也属于同步IO)当一个应用进程对一个非阻塞描述符循环调用recvfrom时,称之为轮询,缺点式耗费cpu. IO复用模型调用select,系统阻塞在这个系统调用上,而不是真正的IO系统调用上,例如进程调用select,等待任一套接字变可读,一旦返回说明某个套接字的状态发生了变化,之后继续处理. 信号驱动式即让内核在描述符就绪时发送信号SIGIO通知进程,可以通过开启套接字的信号驱动式IO功能,通过sigaction系统调用安装一个信号处理函数.这种优势在于等待数据报到达期间进程不被阻塞. 异步IO模型告知内核某个操作,并让内核在整个操作完成后再通知进程. 总结:前四种IO的第一步各不相同,但第二部都一样,都会阻塞等待IO完成.但第五种不会阻塞.","tags":[{"name":"unp","slug":"unp","permalink":"http://yoursite.com/tags/unp/"},{"name":"unix","slug":"unix","permalink":"http://yoursite.com/tags/unix/"},{"name":"socket","slug":"socket","permalink":"http://yoursite.com/tags/socket/"}]},{"title":"字符串匹配KMP算法","date":"2017-03-28T06:09:15.000Z","path":"2017/03/28/字符串匹配KMP算法/","text":"题目:给定一个待匹配字符串和一个模板字符串,要求找到该串中模板字符串首次出现的位置,如果没有则返回-1. 第一种方法:朴素字符串匹配算法,也就是暴力枚举法,对需要匹配的字符串的每个字符进行一次匹配(在这里一次匹配操作是指两个等长字符串匹配),伪代码如下: 123456NAIVE_STRING_MATCHER(T,P)n=T.lengthm=P.lengthfor s=0 to n-m ifP[1..m]==T[s+1..s+m]return s; 其中第五行的操作记为比较两个等长字符串是否相等.类似于strcmp()函数,这些都很好理解,strcmp()复杂度最高为O(L)(L为待匹配字符串长度).所以整个算法时间复杂度为O(M*N) 第二种方法:KMP算法,为了由于朴素算法每一次的不匹配只移动一个偏移量,这会导致之前的已匹配区域重复匹配,为了能确定不匹配时该移动多少偏移量从而能利用之前的信息,所以我们需要一个next数组,也就是能确定当字符不匹配时,模板字符串向右移多少偏移量(数组的值真正记录的是在该位置前缀后缀最大公共长度,也就是该位置长度减去需要的偏移量).举个例子来说: 假设字符串”ababcba”,模板字符串是”abc”, 首先 a b c b a b a 由于c和a不等(此时位置在b,我们确定的是下一个字符匹配) 于是我们只移动模板2个偏移量,继续匹配 a b a a b c b a b a对应于next[2]=0(2-2); a b c 所以关键就是计算next数组. next数组计算伪代码如下: 123456789101112 COMPUTE_PREFIX_FUNCITION(P) m=P.length let next[1..m] be a new array next[1]=0 k=0 for q=2 to m while k&gt;0 and P[k+1]!=P[q] k=next[k] if P[k+1]==P[q] k=k+1next[q]=k; return next; 算法关键就在于第7-8行,while循环的总时间为O(m),从观察k的值开始,第一,在第5行,k初始值为0,并且增加k的唯一方法是通过第10行的递增操作,该操作在第6-11行的for循环中每次最多执行一次,因为k最多增加m-1次,第二,刚进行for循环时,k小于q,并且每次循环q都会增加,所以k永远小于q因此next[q]永远小于q,所以while循环会使q递减.所以while循环最多迭代m-1次. 下面是之前那道题的两种解法:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/*完成函数int strStr(const string&amp; str1,const string str2)功能,找到str1中子串str2的首字符出现的位置,如果没有则返回0 * 暴力解法O(m*n),也可以利用高效的字符串匹配算法例如KMP算法.*/#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;vector&gt;using namespace std;class Solution&#123;public: int strStr(const string&amp; haystack,const string&amp; needle)&#123; if(needle.empty())return 0; auto pos=haystack.begin(); const int N=haystack.size()-needle.size()+1; for(int i=0;i&lt;N;i++)&#123; int j=i; int k=0; while(j&lt;haystack.size()&amp;&amp;k&lt;needle.size()&amp;&amp;haystack[j]==needle[k])&#123; k++; j++; &#125; if(k==needle.size()) return i; &#125; return -1; &#125;&#125;;/*KMP算法.时间复杂度O(M+N),空间复杂度O(M)*/class Solution&#123;public: //KMP主程序,用预处理过的next数组来控制每次不匹配的偏移量,如果莫一个字符不匹配,那么直接找到needle中某一个字符和haystack的下一个字符匹配,这样永远不会回头,总匹配次数最多为字符串长度. int strStr(const string&amp; haystack,const string&amp; needle)&#123; if(needle.size()==0)return 0; vector&lt;int&gt; next=compute_next(needle); int q=-1; for(int i=0;i&lt;haystack.size();i++)&#123; while(q&gt;-1&amp;&amp;haystack[i]!=needle[q+1]) q=next[q]; if(haystack[i]==needle[q+1]) q++; if(q==(needle.size()-1)) return i-q; &#125;return -1; &#125;//用来计算next数组的算法.具体原理参照算法导论32章. static vector&lt;int&gt; compute_next(const string&amp; s)&#123; vector&lt;int&gt; next(s.size(),-1); if(s.size()==0)return next; int q=-1; for(int i=1;i&lt;s.size();i++)&#123; while(q&gt;-1&amp;&amp;s[i]!=s[q+1])//不匹配时要返回的位置 q=next[q]; if(s[i]==s[q+1])//如果下个字符匹配,那么直接继承之前的已匹配区域. q++; next[i]=q; &#125; return next; &#125;&#125;;int main()&#123; string s1=\"ababcd\"; string needle=\"abc\"; Solution s; cout&lt;&lt;s.strStr(s1,needle)&lt;&lt;endl;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"},{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"}]},{"title":"检查带环链表入口问题","date":"2017-03-24T12:21:11.000Z","path":"2017/03/24/检查带环链表入口问题/","text":"这两天一直在做链表的题目,遇到了一道有环链表的问题,感觉很有趣:题目:给一个链表,如果有回路返回回路开始的节点,没有回路则返回NULL 思路:两个指针一快一慢,fas与slow相遇时,fast已经在圈内循环了n圈,设slow走了n步,则fast走了2s步(fast步数还等于s加上在环上多转的n圈),设环长为r,于是: 2s=s+nr s=nr 设整个链表长L,环入口点与相遇点距离为a,起点到环入口点的距离为x,则: x+a=nr=(n-1)r+r=(n-1)r+L-x x=(n-1)r+(L-x-a) L-x-a为相遇点到环入口点的距离,由此可知,从链表头到环入口点等于n-1圈内环+相遇点到入口点,于是我们可以从head开始另设一个指针slow2,两个慢指针 slow2,两个慢指针每次前进一步,它俩一定会在环入口点相遇*/ 2.2.12.cpp1234567891011121314151617181920212223242526#include&lt;iostream&gt;using namespace std;struct ListNode&#123; int val; ListNode* next; ListNode(int x):val(x),next(NULL)&#123;&#125;&#125;;class Solution&#123; ListNode* detectCycle(ListNode* head)&#123; ListNode* slow=head,*fast=head; while(fast&amp;&amp;fast-&gt;next)&#123; slow=slow-&gt;next; fast=fast-&gt;next-&gt;next; if(slow==fast)&#123; ListNode* slow2=head; while(slow2!=slow)&#123; slow2=-&gt;slow2-&gt;next; slow=slow-&gt;next; &#125; return slow2; &#125; &#125; return NULL; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"},{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"}]},{"title":"互斥量和避免死锁","date":"2017-03-15T05:17:04.000Z","path":"2017/03/15/互斥量和避免死锁/","text":"互斥量互斥变量是用pthread_mutex_t数据类型表示的,在使用互斥变量之前,必须首先对它进行初始化,可以把它设置为常量PTHREAD_MUTEX_INITIALIZER(只适用于静态分配的互斥量),也可以调用pthread_mutex_init进行初始化,如果动态分配互斥量,在释放内存前需要调用pthread_mutex_destory.1234567#include&lt;pthread.h&gt;int pthread_mutex_init(pthread_mutex_t* restrict mutex, const pthread_mutexattr_t* restrict attr);int pthread_mutex_destory(pthread_mutex_t* mutex);int pthread_mutex_lock(pthread_mutex_t* mutex);int pthread_mutex_trylock(pthread_mutex_t* mutex); //不阻塞,只尝试加锁,若失败返回EBUSY.int pthread_mutex_unlock(pthread_mutex_t* mutex); 死锁如果线程试图对同一个互斥量加锁两次,那么它自身就会陷入死锁状态,但是使用互斥量时,还有其他不太明显的方式也能产生死锁,例如,程序中使用一个以上的互斥量时,如果允许一个线程一直占用第一个互斥量,并且在试图锁住第二个互斥量时处于阻塞状态,但是拥有第二个互斥量的线程也在师徒锁住第一个互斥量.因为两个线程都在相互请求另一个线程拥有的资源,所以这两个线程都无法向前运行,于是就产生死锁.解决办法就是控制互斥量加锁顺序,比如同时要对互斥量A和B加锁,如果所有线程总是在对B加锁前锁住A,那么使用这两个就不会产生死锁.可以参考下面的例子:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;const int NHASH=29;#define HASH(id) (((unsigned long)id)%NHASH)pthread_mutex_t hashlock=PTHREAD_MUTEX_INITIALIZER;struct foo&#123; int f_count; pthread_mutex_t f_lock; int f_id; struct foo* f_next;//protected by hashlock&#125;;struct foo* fh[NHASH];struct foo* foo_alloc(int id)&#123; struct foo* fp; int idx; if((fp=(struct foo*)malloc(sizeof(struct foo)))!=NULL)&#123; fp-&gt;f_count=1; fp-&gt;f_id=id; if(pthread_mutex_init(&amp;fp-&gt;f_lock,NULL)!=0)&#123; free(fp); return NULL; &#125; idx=HASH(id); pthread_mutex_lock(&amp;hashlock); fp-&gt;f_next=fh[idx]; fh[idx]=fp; pthread_mutex_lock(&amp;fp-&gt;f_lock); pthread_mutex_unlock(&amp;hashlock); &#125; return fp;&#125;void foo_hold(struct foo* fp)&#123; pthread_mutex_lock(&amp;fp-&gt;f_lock); fp-&gt;f_count++; pthread_mutex_unlock(&amp;fp-&gt;f_lock);&#125;struct foo* foo_find(int id)&#123; struct foo* fp; pthread_mutex_lock(&amp;hashlock); for(fp=fh[HASH(id)];fp!=NULL;fp=fp-&gt;f_next)&#123; if(fp-&gt;f_id==id)&#123; fp-&gt;f_count++; break; &#125; &#125; pthread_mutex_unlock(&amp;hashlock); return fp;&#125;//第一个版本的释放函数,严格按照每种互斥量的功能来锁住临界区,由于需要考虑互斥量使用顺序,会导致代码变得复杂.(foo_rele函数中先上锁在观察是否需要修改fh散列表,如果需要修改则必须先解锁在按顺序上锁)void foo_rele(struct foo* fp)&#123; struct foo* tfp; int idx; pthread_mutex_lock(&amp;fp-&gt;f_lock); if(fp-&gt;f_count==1)&#123; pthread_mutex_unlock(&amp;fp-&gt;f_lock); pthread_mutex_lock(&amp;hashlock); pthread_mutex_lock(&amp;fp-&gt;f_lock); if(fp-&gt;f_count!=1)&#123; fp-&gt;f_count--; pthread_mutex_unlock(&amp;fp-&gt;f_lock); pthread_mutex_unlock(&amp;hashlock); return; &#125;else&#123; idx=HASH(fp-&gt;f_id); tfp=fh[idx]; if(tfp==fp)&#123; fh[idx]=fp-&gt;f_next; &#125;else&#123; while(tfp-&gt;f_next!=fp) tfp=tfp-&gt;f_next; tfp-&gt;f_next=fp-&gt;f_next; &#125; &#125; pthread_mutex_unlock(&amp;fp-&gt;f_lock); pthread_mutex_unlock(&amp;hashlock); pthread_mutex_destory(&amp;fp-&gt;f_lock); free(fp); &#125;else&#123; fp-&gt;f_count--; pthread_mutex_unlock(&amp;fp-&gt;f_lock); &#125;&#125;//第二个版本的释放函数.直接用hashlock来锁住对fp的操作,避免了两个互斥量使用的顺序问题.简化了代码.但是线程阻塞的概率会更大,因为hashlock使用的范围更大.需要权衡两者的使用.void foo_rele2(struct foo* fp)&#123; struct foo* tfp; int idx; pthread_mutex_lock(&amp;hashlock); if(--fp-&gt;f_count==0)&#123; idx=HASH(fp-&gt;f_id); tfp=fh[idx]; if(tfp==fp)&#123; fh[idx]=fp-&gt;f_next; &#125;else&#123; while(tfp-&gt;f_next!=fp) tfp=tfp-&gt;f_next; tfp-&gt;f_next=fp-&gt;f_next; &#125; pthread_mutex_unlock(&amp;hashlock); pthread_mutex_destory(&amp;fp-&gt;f_lock); free(fp); &#125;else pthread_mutex_unlock(&amp;hashlock);&#125;","tags":[{"name":"apue","slug":"apue","permalink":"http://yoursite.com/tags/apue/"},{"name":"c","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"fork()和vfork()的总结","date":"2017-03-04T07:04:27.000Z","path":"2017/03/04/fork-和vfork-的总结/","text":"fork()函数可以创建一个新的进程,被称为子进程,子进程获得父进程数据空间,堆和栈的副本.父子进程不共享这些存储空间部分,共享正文段. 看下面一个实例:8.3.c/*打印父子进程的输出*/123456789101112131415161718192021#include \"apue.h\" int globvar= 6;char buf[] = \"a write to stdout\\n\"int main()&#123; int var; pid_t pid; var=88; if(write(STDOUT_FILENO,buf,sizeof(buf)-1)!=sizeof(buf)-1) err_sys(\"write error\"); printf(\"before fork\\n\"); if((pid=fork())&lt;0) err_sys(\"fork error\"); else if(pid==0)&#123; globvar++; var++; &#125;else sleep(2); printf(\"pid=%ld,glob=%d,var=%d\\n\",(long)getpid(),globvar,var); exit(0);&#125; 运行后结果:123456$ gcc 8.3.c -o8.3 -lapue$ ./8.3a write to stdoutbefore forkpid=5423,glob=7,var=89pid=5422,glob=6,var=88一切正常运行,但是如果我们重定向标准输出流之后:1234567$ ./8.3 &gt; temp.out$ cat temp.outa write to stdoutbefore forkpid=5481,glob=7,var=89before forkpid=5480,glob=6,var=88 可以看到printf输出了两次,原因是在fork()之前调用了一次printf一次,但当调用fork()时,该行数据还在缓冲区中(因为重定向之后为全缓冲),然后讲父进程数据空间复制到子进程中时,该缓冲区数据也被复制到子进程中,此时父进程和子进程各自有了带该行内容的缓冲区.当进程终止时,缓冲区内容被刷新写到文件中. 子进程和父进程之间的区别如下: fork返回值不同(进程ID不同)子进程不继承父进程设置的文件锁子进程的未处理闹钟被清除.子进程的未处理信号集设置为空集.有时候实际用户ID的进程总数超过了系统限制,会导致fork()失败. vfork()函数用于创建一个新进程,而该进程的目的是exec一个新程序.vfork()不会将父进程的地址空间完全复制到子进程中,另一个区别是,vfork()保证子进程先运行,在它调用exec或exit之后父进程才可能被调度运行,当子进程调用这两个函数中的任意一个时,父进程会恢复运行.(如果在调用这两个函数之前子进程依赖父进程的进一步动作会导致死锁.)引用网上的一个说法:为什么会有vfork，因为以前的fork 很傻， 它创建一个子进程时，将会创建一个新的地址空间，并且拷贝父进程的资源，而往往在子进程中会执行exec 调用，这样，前面的拷贝工作就是白费力气了，这种情况下，聪明的人就想出了vfork，它产生的子进程刚开始暂时与父进程共享地址空间（其实就是线程的概念了），因为这时候子进程在父进程的地址空间中运行，所以子进程不能进行写操作，并且在儿子 霸占”着老子的房子时候，要委屈老子一下了，让他在外面歇着（阻塞），一旦儿子执行了exec 或者exit 后，相 于儿子买了自己的房子了，这时候就相当于分家了。","tags":[{"name":"apue","slug":"apue","permalink":"http://yoursite.com/tags/apue/"}]},{"title":"递归降序遍历目录结构","date":"2017-03-03T02:06:09.000Z","path":"2017/03/03/递归降序遍历目录结构/","text":"参考apue第四章代码:4.22.c/*此程序用来递归降序遍历文件层次结构,命令行传入一个参数作为起点路径名.*/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161#include&lt;errno.h&gt;#include\"apue.h\"#include&lt;limits.h&gt;//定义了数据类型的范围.例如INT_MAX宏为该环境下int类型的最大值.#include&lt;dirent.htypedef int Myfunc(const char*,const struct stat*,int);char* path_alloc(size_t*);static Myfunc myfunc;static int myftw(char*,Myfunc*);static int dopath(Myfunc*);static long nreg,ndir,nblk,nchr,nfifo,nslink,nsock,ntot;int main( int argc,char** argv)&#123; int ret; if(argc!=2) err_quit(\"Usage: ftw &lt;starting-pathname&gt;\"); ret=myftw(argv[1],myfunc); ntot=nreg+ndir+nblk+nchr+nfifo+nslink+nsock; if(ntot==0) ntot=1; printf(\"regular files= %7ld,%5.12f %%\\n\",nreg,nreg*100.0/ntot); printf(\"directories = %7ld,%5.12f %%\\n\",ndir,ndir*100.0/ntot); printf(\"block special = %7ld,%5.12f %%\\n\",nblk,nblk*100.0/ntot); printf(\"char special = %7ld,%5.12f %%\\n\",nchr,nchr*100.0/ntot); printf(\"FIFOS = %7ld,%5.12f %%\\n\",nfifo,nfifo*100.0/ntot); printf(\"symbolic links = %7ld,%5.12f %%\\n\",nslink,nslink*100.0/ntot); printf(\"sockets = %7ld,%5.12f %%\\n\",nsock,nsock*100.0/ntot); exit(ret);&#125;/*文件名路径分配函数#ifdef PATH_MAXstatic long pathmax = PATH_MAX;#elsestatic long pathmax = 0;#endifstatic long posix_version = 0;static long xsi_version = 0;/* If PATH_MAX is indeterminate, no guarantee this is adequate */#define PATH_MAX_GUESS 1024char *path_alloc(size_t *sizep) /* also return allocated size, if nonnull */&#123; char *ptr; size_t size; if (posix_version == 0) posix_version = sysconf(_SC_VERSION); if (xsi_version == 0) xsi_version = sysconf(_SC_XOPEN_VERSION); if (pathmax == 0) &#123; /* first time through */ errno = 0; if ((pathmax = pathconf(\"/\", _PC_PATH_MAX)) &lt; 0) &#123; if (errno == 0) pathmax = PATH_MAX_GUESS; /* it's indeterminate */ else err_sys(\"pathconf error for _PC_PATH_MAX\"); &#125; else &#123; pathmax++; /* add one since it's relative to root */ &#125; &#125; /* * Before POSIX.1-2001, we aren't guaranteed that PATH_MAX includes * the terminating null byte. Same goes for XPG3. */ if ((posix_version &lt; 200112L) &amp;&amp; (xsi_version &lt; 4)) size = pathmax + 1; else size = pathmax; if ((ptr = malloc(size)) == NULL) err_sys(\"malloc error for pathname\"); if (sizep != NULL) *sizep = size; return(ptr);&#125;#define FTW_F 1#define FTW_D 2#define FTW_DNR 3#define FTW_NS 4static char* fullpath;static size_t pathlen;static int myftw(char* pathname,Myfunc* func)&#123; fullpath=path_alloc(&amp;pathlen); if(pathlen&lt;=strlen(pathname))&#123; pathlen=strlen(pathname)*2; if((fullpath=realloc(fullpath,pathlen))==NULL) err_sys(\"realloc failed\"); &#125; strcpy(fullpath,pathname); return dopath(func);&#125;/*用来递归调用myfunc来处理路径内的每个文件.static int dopath(Myfunc* func)&#123; struct stat statbuf; struct dirent* dirp; DIR* dp; int ret,n; if(lstat(fullpath,&amp;statbuf)&lt;0) return func(fullpath,&amp;statbuf,FTW_NS); if(S_ISDIR(statbuf.st_mode)==0) return(func(fullpath,&amp;statbuf,FTW_F)); if(ret=func(fullpath,&amp;statbuf,FTW_D)!=0) return ret; n=strlen(fullpath); if(n+NAME_MAX+2&gt;pathlen)&#123; pathlen*=2; if((fullpath=realloc(fullpath,pathlen))==NULL) err_sys(\"realloc failed\"); &#125; fullpath[n++]='/'; fullpath[n]=0; if((dp=opendir(fullpath))==NULL) return func(fullpath,&amp;statbuf,FTW_DNR); while((dirp=readdir(dp))!=NULL)&#123; if(strcmp(dirp-&gt;d_name,\".\")==0||strcmp(dirp-&gt;d_name,\"..\")==0) continue; strcpy(&amp;fullpath[n],dirp-&gt;d_name); if((ret=dopath(func))!=0) break; &#125; fullpath[n-1]=0; closedir(dp); return ret;&#125;/*用来判断输入路径的文件类型,也可能是目录文件*/static int myfunc(const char* pathname,const struct stat* statptr,int type)&#123; switch(type)&#123; case FTW_F: if(S_ISREG(statptr-&gt;st_mode)) nreg++; if(S_ISBLK(statptr-&gt;st_mode)) ndir++; if(S_ISCHR(statptr-&gt;st_mode)) nchr++; if(S_ISFIFO(statptr-&gt;st_mode)) nfifo++; if(S_ISLNK(statptr-&gt;st_mode)) nslink++; if(S_ISSOCK(statptr-&gt;st_mode)) nsock++; break; case FTW_D: ndir++; break; case FTW_DNR: err_ret(\"Can't read directory %s\",pathname); break; case FTW_NS: err_ret(\"stat error for %s\",pathname); break; &#125; return 0;&#125; 运行结果如下:12345678$ /home/wangliang/apue/4.22 /regular files= 389832,70.403768044225 %directories = 61804,11.161819656173 %block special = 0,0.000000000000 %char special = 230,0.041538064218 %FIFOS = 6,0.001083601675 %symbolic links = 101781,18.381677018073 %sockets = 56,0.010113615636 %","tags":[{"name":"apue","slug":"apue","permalink":"http://yoursite.com/tags/apue/"}]},{"title":"typedef总结","date":"2017-03-02T02:23:58.000Z","path":"2017/03/02/typedef总结/","text":"今天在apue上看到如下定义:4.22.c12typedef int Myfunc(const char*,const struct stat*,int);static Myfunc myfunc;于是翻了一下c primer 复习了一下typedef的用法:1.自定义变量别名. 2.自定义结构体名称1234typedef struct &#123; float real; float imag;&#125;COMPLEX;3.定义复杂类型:1typedef char(* FRPTC())[5];这句话把frptc声明为一个函数类型,该函数返回一个指向5个元素的char数组的指针.对复杂变量的声明,只要记住在传统声明定义表达式里用类型名代替变量名,然后在开头加上typedef.对于理解复杂声明声明可用的“右左法则”：从变量名看起，先往右，再往左，碰到一个圆括号就调转阅读的方向；括号内分析完就跳出括号，还是按先右后左的顺序，如此循环，直到整个声明分析完。举例：int (func[5])(int );func右边是一个[]运算符，说明func是具有5个元素的数组；func的左边有一个，说明func的元素是指针（注意这里的不是修饰func，而是修饰func[5]的，原因是[]运算符优先级比高，func先跟[]结合）。跳出这个括号，看右边，又遇到圆括号，说明func数组的元素是函数类型的指针，它指向的函数具有int类型的形参，返回值类型为int。","tags":[{"name":"apue","slug":"apue","permalink":"http://yoursite.com/tags/apue/"},{"name":"c/c++","slug":"c-c","permalink":"http://yoursite.com/tags/c-c/"}]},{"title":"apue学习笔记1-exec函数总结","date":"2017-02-27T07:46:57.000Z","path":"2017/02/27/apue学习笔记1-exec函数总结/","text":"这学期开始看apue第三版,并记录相关知识点的笔记.首先复习exec函数的使用. exec函数总共有七个:123456789#include&lt;unistd.h&gt;int execl(const char* pathname,const char* arg0,.../*(char* )0 */);int execv(const char* pathname,char* const argv[]);int execle(const char* pathname,const char* arg0,... /* (char*)0,char* const envp[]*/);int execve(const char* pathname,char* const argv[],char* const envp[]);int execlp(const char* filename,const char* arg0,.../*(char*)0 */);int execvp(const char* filename,char* const argv[]);int fexecve(int fd,char* const argv[],char *const envp[]); 函数之间第一个区别在前4个取路径做参数,后两个函数取文件名做参数,最后一个取文件描述符.也就是说后两个函数可以从环境变量PATH中寻找.第二个区别与参数表有关,以const char* arg0,arg1…传入的为参数列表,需要以空指针做结尾第三个区别环境变量：exec函数族使用了系统默认的环境变量，也可以传入指定的环境变量。这里以“e”（environment）结尾的两个函数execle、execve就可以在envp[]中指定当前进程所使用的环境变量替换掉该进程继承的所以环境变量。这七个只有execve是内核的系统调用,其他的都是库函数.上代码实例:exec.c/*echoall程序用来打印命令行参数和环境表 */123456789101112131415161718#include\"apue.h\"#include&lt;unistd.h&gt;int main(int argc,char** argv)&#123; pid_t pid; char** env_init=&#123;\"USER=unknown\",\"PATH=/tmp\",NULL&#125;; if((pid=fork())&lt;0)&#123; err_sys(\"fork error\"); &#125;else if(pid==0)&#123; if(execle(\"/home/wangliang/bin/echoall\",\"echoall\",\"myarg1\",\"MY ARG2\",(char*)0,env_init)&lt;0) err_sys(\"execle error\"); &#125; if(waitpid(pid,NULL,0)&lt;0) error_sys(\"wait error\"); if((pid=fork)==0) if(execlp(\"echoall\",\"echoall\",\"only 1arg\",(char*)0)&lt;0) err_sys(\"execlp() error\"); exit(0);&#125;","tags":[{"name":"apue","slug":"apue","permalink":"http://yoursite.com/tags/apue/"}]},{"title":"利用hexo和githubpage搭建个人博客","date":"2017-02-26T13:03:23.000Z","path":"2017/02/26/利用hexo和github-page-搭建个人博客/","text":"最近博主花了几天的时间终于搭建好了自己的小窝,也是在入坑爬坑的过程弄出来了,参照网上的一些资料教程,自己总结的一套方法如下: 安装node.js Node.js是一个开放源代码、跨平台的、可用于服务器端和网络应用的运行环境，该应用由 C++ 语言写成，在 Node.js 运行时运行。Node.js 提供事件驱动和非阻塞 I/O API，可优化应用程序的吞吐量和规模。这些技术通常被用于实时应用程序。并且它是采用 Google 的 V8 引擎来执行代码，它的大部分基本模块都是用 JavaScript 写成的，包含有一系列内置模块，使得程序可以作为独立服务器运行，从而脱离 Apache HTTP Server 或 IIS 运行。而 npm 也即 Node包管理器（Node Package Manager），它是一个以 Javascript 编写的软件包管理系统，默认环境为 Node.js 。 所以首先得安装node.js和npm,命令如下:12$ sudo apt-get install nodejs$ sudo apt-get install npm或者从官网上下载对应平台的版本进行安装.可以用命令node -v如果出现版本号则安装成功.接下来安装nrm,是npm的资源管理器:1$ sudo npm install nrm -g --registry https://registry.npm.taobao.org接下来设置下载源为淘宝源(防止默认下载源速度慢超时):1$ nrm use taobao可能出现命令未识别,则说明没有全局安装,这时候需要你用ln命令将你下载的可执行文件链接到usr/local/bin/目录下.(如果正常则跳过)1$ ln -s &lt;下载文件&gt; usr/local/bin/&lt;文件名&gt;接下来需要下载hexo,可用如下命令(记住加上-g进行全局安装):1$ sudo npm install hexo -g 安装git工具然后需要安装git工具,需要了解git和如何使用的话可以查阅 git安装教程 搭建博客接下来开始搭建,在自己的主目录下创建Blog目录并生成初始框架:1234$ mkdir Blog &amp;&amp; cd Blog$ hexo init$ hexo generate$ hexo server打开浏览器输入localhost:4000可看到已经生成的初始界面.因为通过hexo server已经运行了本地的服务器进入目录 /home/shiyanlou/Code/Hexo/blog/themes ，下载并解压缩 Next 主题。12$ wget http://labfile.oss.aliyuncs.com/courses/700/next.zip$ unzip next.zip编辑 ~/Blog/config.yml文件,修改主题那一行theme: next(记住选项冒号之后都有空格)可以自行修改其他信息,每次修改后都要执行hexo clean和hexo g命令,关于如何使用hexo和添加自己的文章,修改样式等请参阅: hexo中文官网教程 部署到github如上操作完只是在本地生成了你的静态主页,我们需要传到github仓库里这样别人访问你的仓库就可以自动展示你的博客.首先打开你的github创建一个新的仓库,仓库名格式为:你的git账户名.github.io.如下图:进入Blog目录下,同步你的仓库:1$ git clone [你的仓库的url] 仓库url可以在下图获得:一路顺利后,打开 Blog目录下的config.yml文件,在最下面修改:1234deploy: type: git respository: https://github.com/[你的github用户名]/[你的github用户名].github.io.git branch: master再执行命令:12$ npm install hexo-deployer-git --save$ hexo d然后在浏览器浏览http://[你的github用户名]/github.io至此,初步的搭建已经完成,接下来就是参阅markdown语法和hexo教程来多写文章吧.","tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"},{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"博客","slug":"博客","permalink":"http://yoursite.com/tags/博客/"}]}]